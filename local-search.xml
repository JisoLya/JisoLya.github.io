<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Qwen&amp;GPT2 模型架构</title>
    <link href="/2026/01/19/Qwen-GPT2-architecture/"/>
    <url>/2026/01/19/Qwen-GPT2-architecture/</url>
    
    <content type="html"><![CDATA[<h1 id="GPT2-Qwen2-模型架构"><a href="#GPT2-Qwen2-模型架构" class="headerlink" title="GPT2&#x2F;Qwen2 模型架构"></a>GPT2&#x2F;Qwen2 模型架构</h1><h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><p>在介绍GPT2与Qwen2的模型架构前，首先需要简单的回顾一下Transformer架构，这里就默认读者已经基本了解Transformer了，贴出一个图。<br><img src="/2026/01/19/Qwen-GPT2-architecture/transformer.png" alt="Transformer"></p><p>左侧是Encoder部分而右侧是Decoder部分。至于为什么需要将Encoder的输出输入到Decoder当中，以一个机器翻译任务举例。我爱你 -&gt; I love you</p><p>首先Encoder的输入为原始的词嵌入，位置编码信息，这部分在另一篇文档中给出了。至于为什么是mask-MultiHead att：在Encoder中我们需要把不同batch(也就是不同的句子集合)都padding为相同的长度，这样适合于向量化运算，所以计算self-att的时候需要把padding的部分mask掉(因为句子这里本身是没有任何消息的)。至于在Bert（Masked Language Modeling - MLM）预训练过程中，他们更类似于做”完形填空”，mask是用来挖空的。</p><blockquote><p>举个例子： 我 [masked] 你</p></blockquote><p>经过Encoder的处理之后，输出的矩阵被复制一份，分别经过两个线性层作为Decoder的K与V，作为Decoder中att的输入。</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs gherkin">Encoder 输出的同一个矩阵<br>       |<span class="hljs-string"></span><br><span class="hljs-string">       +---------------------+</span><br><span class="hljs-string">       </span>|<span class="hljs-string">                     </span>|<br>       v                     v<br>[线性变换 W_k]          [线性变换 W_v]<br>       |<span class="hljs-string">                     </span>|<br>       v                     v<br>   第一部分：Key (K)      第二部分：Value (V)<br>   (用来被 Query 匹配)     (用来被加权提取)<br>           \             /<br>            \           /<br>             \         /<br>         输入到 Decoder 的 Cross-Attention<br></code></pre></td></tr></table></figure><p>其次是Decoder的输入，图中标出了一个Shift-Right，这里是因为Decoder是一个自回归的模型。</p><blockquote><p>通俗的来说 Decoder的预测方式是这样的 [&lt;start&gt;, 预测下一个词] -&gt; [&lt;start&gt;, 单词1, 预测下一个词]，Decoder在预测下一个词的时候需要知道前文。如果直接将原本的词嵌入输入，Decoder是缺失第一个开始标记的(从无到第一个单词的过程)。 所以输入的时候Transformer作为有监督的学习，将输入右移就是添加了开始标记[&lt;start&gt;,我, 爱, 你]</p></blockquote><p>另一点是计算注意力分数的时候同样是Masked Att， 这里mask是为了保证在训练的时候保证<strong>因果性</strong>, Decoder属于是预测下一个词，如果提前把下一个词告诉他那么这个预测就没有意义了。</p><h2 id="GPT2-GPT3模型结构"><a href="#GPT2-GPT3模型结构" class="headerlink" title="GPT2&#x2F;GPT3模型结构"></a>GPT2&#x2F;GPT3模型结构</h2><p>GPT系列使用了Transformer的Decoder架构，他是Decoder-only的模型，相较于原始的transformer，他去掉了中间的Cross-att模块，并经过多次堆叠，大概示例如下:</p><p><img src="/2026/01/19/Qwen-GPT2-architecture/DecoderOnly.png" alt="去掉的Cross-Att模块"></p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs gherkin">[Input]<br>   |<span class="hljs-string"></span><br><span class="hljs-string">[Token Emb] + [Positional Emb (可学习的)]</span><br><span class="hljs-string">   </span>|<br>   |<span class="hljs-string">--- (堆叠 N 层 Block) ---</span><br><span class="hljs-string">   </span>|<span class="hljs-string">  [Block i]</span><br><span class="hljs-string">   </span>|<span class="hljs-string">     </span>|<br>   |<span class="hljs-string">  [Layer Norm]  &lt;-- Pre-Norm</span><br><span class="hljs-string">   </span>|<span class="hljs-string">     </span>|<br>   |<span class="hljs-string">  [Masked Self-Attention]</span><br><span class="hljs-string">   </span>|<span class="hljs-string">     </span>|<br>   |<span class="hljs-string">  [Add] (残差连接直接连到 Norm 之前)</span><br><span class="hljs-string">   </span>|<span class="hljs-string">     </span>|<br>   |<span class="hljs-string">  [Layer Norm]</span><br><span class="hljs-string">   </span>|<span class="hljs-string">     </span>|<br>   |<span class="hljs-string">  [FFN]</span><br><span class="hljs-string">   </span>|<span class="hljs-string">     </span>|<br>   |<span class="hljs-string">  [Add]</span><br><span class="hljs-string">   </span>|<span class="hljs-string">-------------------------</span><br><span class="hljs-string">   </span>|<br>[Layer Norm] (最后的归一化)<br>   |<span class="hljs-string"></span><br><span class="hljs-string">[Linear Projection] (映射回词表大小)</span><br><span class="hljs-string">   </span>|<br>[Softmax]<br></code></pre></td></tr></table></figure><p>另外他还把归一化提前到了att层前，曾经是post-norm，现在采用了pre-norm。下边是一些模型的参数：<br><img src="/2026/01/19/Qwen-GPT2-architecture/model_para.png" alt="alt text"></p><p>至于GPT3， 他是GPT2堆料的版本，但是采用了新的Sparse-Att技术，因为原有的注意力机制每个单词需要查看他之前所有的单词来获取注意力分数，这个时间复杂度是O(N^2)的，导致显存爆炸。这里的Sparse-Att是有策略地计算注意力分数而不是全局计算。</p><p>GPT3还提出了一个概念叫做In-Context-Learning， 我认为这和现在的提示词&#x2F;上下文工程很相似，本质上是因为LLM在训练的过程中有过这样的训练样本，类似与 “问题， 答案”这样的。所以在模型中加入一些Context可以有效地提升模型回答的准确率。</p><h2 id="Qwen模型架构"><a href="#Qwen模型架构" class="headerlink" title="Qwen模型架构"></a>Qwen模型架构</h2><p>这部分过两天再更新~</p>]]></content>
    
    
    
    <tags>
      
      <tag>Transformer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CUDA实现并行求和</title>
    <link href="/2026/01/18/cuda%E5%AE%9E%E7%8E%B0%E6%95%B0%E7%BB%84%E5%B9%B6%E8%A1%8C%E6%B1%82%E5%92%8C/"/>
    <url>/2026/01/18/cuda%E5%AE%9E%E7%8E%B0%E6%95%B0%E7%BB%84%E5%B9%B6%E8%A1%8C%E6%B1%82%E5%92%8C/</url>
    
    <content type="html"><![CDATA[<h1 id="CUDA中的网格跨步循环"><a href="#CUDA中的网格跨步循环" class="headerlink" title="CUDA中的网格跨步循环"></a>CUDA中的网格跨步循环</h1><p>参考 <a href="https://www.codeleading.com/article/6260306169/">https://www.codeleading.com/article/6260306169/</a><br>cuda中的kernel我们一般会这样写</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">parallel_run</span><span class="hljs-params">(<span class="hljs-type">int</span> n)</span></span>&#123;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = threadIdx.x + blockIdx.x * blockDim.x;i &lt; n;i += blockDim.x * gridDim.x)&#123;<br>        <span class="hljs-comment">//doing something..</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><blockquote><p>这里是对于网格跨步循环的官方解释：<br>Notice that the stride of the loop is blockDim.x * gridDim.x which is the total number of threads in the grid. So if there are 1280 threads in the grid, thread 0 will compute elements 0, 1280, 2560, etc. This is why I call this a grid-stride loop. By using a loop with stride equal to the grid size, we ensure that all addressing within warps is unit-stride, so we get maximum memory coalescing, just as in the monolithic version.</p></blockquote><p>也就是说如果一个网格内有1280个线程，那么thread_0会计算成员的0,1280,2560…等一系列的数组索引。也就是线程1会同时将for循环内的操作应用到这一系列索引，从而实现了并行计算。</p><h1 id="TLS（Thread-local-Storage）"><a href="#TLS（Thread-local-Storage）" class="headerlink" title="TLS（Thread-local-Storage）"></a>TLS（Thread-local-Storage）</h1><p>如果我们需要对一个数组进行求和，利用网格跨步循环可以实现并行计算。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">parallel_for</span><span class="hljs-params">(<span class="hljs-type">int</span> n, <span class="hljs-type">int</span>* sum, <span class="hljs-type">int</span> *arr)</span></span>&#123;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = threadIdx.x + blockDim.x * blockIdx.x;<br>    i &lt; n; i += gridDim.x * blockDim.x)&#123;<br>        <span class="hljs-comment">//我们很自然的想到了</span><br>        &amp;sum[<span class="hljs-number">0</span>] += arr[i];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>但是实际的运行下来我们会发现结果并不等于数组的和，这是因为我们的这一条语句<code>*sum += arr[i];</code>会被编译器解释为一系列的操作1. 读取寄存器1的值 2. 读取寄存器2的值 3. 寄存器1+寄存器2 4. 写回到数组中。</p><p>在多线程环境下就会出现data race， 所以我们需要保证原子化的操作。可以直接使用<code>cudaruntime.h</code>为我们提供的<code>atomicAdd()</code>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-built_in">atomicAdd</span>(sum, arr[i]);<br></code></pre></td></tr></table></figure><p>这样的输出结果就是正确的了，但是又引入的新的问题，每一个线程都进行原子化的add操作，也就是将循环串行化了，就放弃了GPU并行计算的能力。该怎样进一步优化呢？</p><p>这就是TLS技术了，我们可以让每一个线程都进行线程本地存储,最后再进行相加。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">parallel_for</span><span class="hljs-params">(<span class="hljs-type">int</span> n, <span class="hljs-type">int</span>* sum, <span class="hljs-type">int</span> *arr)</span></span>&#123;<br>    <span class="hljs-type">int</span> local_sum = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = threadIdx.x + blockDim.x * blockIdx.x;<br>    i &lt; n; i += gridDim.x * blockDim.x)&#123;<br>        <span class="hljs-comment">//我们很自然的想到了</span><br>        local_sum += arr[i];<br>    &#125;<br><br>    <span class="hljs-built_in">atomicAdd</span>(&amp;sum[<span class="hljs-number">0</span>], local_sum);<br>&#125;<br></code></pre></td></tr></table></figure><p>这样就实现了一个数组的求和操作。</p>]]></content>
    
    
    
    <tags>
      
      <tag>CUDA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CUDA共享内存</title>
    <link href="/2026/01/18/cuda%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98/"/>
    <url>/2026/01/18/cuda%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98/</url>
    
    <content type="html"><![CDATA[<h1 id="CUDA共享内存"><a href="#CUDA共享内存" class="headerlink" title="CUDA共享内存"></a>CUDA共享内存</h1><h2 id="SM-Streaming-Multiprocessors-与板块-block"><a href="#SM-Streaming-Multiprocessors-与板块-block" class="headerlink" title="SM(Streaming Multiprocessors)与板块(block)"></a>SM(Streaming Multiprocessors)与板块(block)</h2><p>在先前我们利用网格跨步循环实现了数组的加法，但是其中利用了<code>atomicAdd()</code>这样的原子化操作导致实际上每一个线程都是串行化进行了，并不能发挥GPU的并行计算能力。</p><p>如果不使用原子计算的方式，我们就要将sum变为数组，下边的这段代码每一个线程计算一段地址0-1023， 1024-2045 …，将求和的大小缩减到CPU可接受的范围，最后在CPU上进行求和。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global <span class="hljs-type">void</span> <span class="hljs-title">parallel_sum</span><span class="hljs-params">(<span class="hljs-type">int</span>* sum, <span class="hljs-type">int</span> <span class="hljs-type">const</span>* arr, <span class="hljs-type">int</span> n)</span></span>&#123;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;i &lt; n / <span class="hljs-number">1024</span> ;i += blockDim.x * gridDim.x)&#123;<br>        <span class="hljs-type">int</span> local_sum = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = i * <span class="hljs-number">1024</span>; j &lt; i * <span class="hljs-number">1024</span> + <span class="hljs-number">1024</span>;j++)&#123;<br>            local_sum += arr[j];<br>        &#125;<br>        sum[i] = local_sum;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这种求和的内存访问有很大的缺点，每个线程内部仍旧是串行化的：</p><ul><li>线程0依次访问arr[0], arr[1]…</li><li>线程1依次访问arr[1024], arr[1025]…</li></ul><p>在上述的方式里，<code>local_sum</code>对前一时刻是有依赖关系的，去除依赖关系是提升效率的关键。</p><blockquote><p>利用线程局部数组来并行化处理</p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">parallel_sum</span><span class="hljs-params">(<span class="hljs-type">int</span>* sum, <span class="hljs-type">int</span> <span class="hljs-type">const</span>*  arr, <span class="hljs-type">int</span> n)</span></span>&#123;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = threadIdx.x + blockDim.x * blockIdx.x;<br>    i &lt; n / <span class="hljs-number">1024</span>; i += blockDim.x * gridDim.x)&#123;<br>        <span class="hljs-type">int</span> local_sum[<span class="hljs-number">1024</span>];<br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j &lt; <span class="hljs-number">1024</span>;j++)&#123;<br>            local_sum[j] = arr[i * <span class="hljs-number">1024</span> + j];<br>        &#125;<br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j &lt; <span class="hljs-number">512</span>;j++)&#123;<br>            local_sum[j] += local_sum[j + <span class="hljs-number">512</span>];<br>        &#125;<br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j &lt; <span class="hljs-number">256</span>;j++)&#123;<br>            local_sum[j] += local_sum[j + <span class="hljs-number">256</span>];<br>        &#125;<br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j &lt; <span class="hljs-number">128</span>;j++)&#123;<br>            local_sum[j] += local_sum[j + <span class="hljs-number">128</span>];<br>        &#125;<br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j &lt; <span class="hljs-number">64</span>;j++)&#123;<br>            local_sum[j] += local_sum[j + <span class="hljs-number">64</span>];<br>        &#125;<br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j &lt; <span class="hljs-number">32</span>;j++)&#123;<br>            local_sum[j] += local_sum[j + <span class="hljs-number">32</span>];<br>        &#125;<br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j &lt; <span class="hljs-number">16</span>;j++)&#123;<br>            local_sum[j] += local_sum[j + <span class="hljs-number">16</span>];<br>        &#125;<br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j &lt; <span class="hljs-number">8</span>;j++)&#123;<br>            local_sum[j] += local_sum[j + <span class="hljs-number">8</span>];<br>        &#125;<br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j &lt; <span class="hljs-number">4</span>;j++)&#123;<br>            local_sum[j] += local_sum[j + <span class="hljs-number">4</span>];<br>        &#125;<br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j &lt; <span class="hljs-number">2</span>;j++)&#123;<br>            local_sum[j] += local_sum[j + <span class="hljs-number">2</span>];<br>        &#125;<br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j &lt; <span class="hljs-number">1</span>;j++)&#123;<br>            local_sum[j] += local_sum[j + <span class="hljs-number">1</span>];<br>        &#125;<br>        sum[i] = local_sum[<span class="hljs-number">0</span>];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Shared-Memory"><a href="#Shared-Memory" class="headerlink" title="Shared Memory"></a>Shared Memory</h2><p>上面已经实现了无数据依赖可以并行的for循环， 那么如何将他变成真正的并行？对于上面的无数据依赖的for，我们可以将线程升级为板块(block),线程局部数组升级为板块局部数组。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__void <span class="hljs-title">parallel_sum</span><span class="hljs-params">(<span class="hljs-type">int</span> *sum, <span class="hljs-type">int</span> <span class="hljs-type">const</span>* arr, <span class="hljs-type">int</span> n)</span></span>&#123;<br>    __shared__ <span class="hljs-type">int</span> local_sum[<span class="hljs-number">1024</span>];<br><br>    <span class="hljs-type">int</span> i = threadIdx.x;<br>    <span class="hljs-type">int</span> j = blockIdx.x;<br><br>    local_sum[j] = arr[i * <span class="hljs-number">1024</span> + j];<br>    __syncthreads();<br>    <br>    <span class="hljs-keyword">if</span> (j &lt; <span class="hljs-number">512</span>)&#123;<br>        local_sum[j] += local_sum[j + <span class="hljs-number">512</span>];<br>    &#125;<br>    __syncthreads();<br><br>    <span class="hljs-keyword">if</span> (j &lt; <span class="hljs-number">256</span>)&#123;<br>        local_sum[j] += local_sum[j + <span class="hljs-number">256</span>];<br>    &#125;<br>    __syncthreads();<br><br>    <span class="hljs-keyword">if</span> (j &lt; <span class="hljs-number">128</span>)&#123;<br>        local_sum[j] += local_sum[j + <span class="hljs-number">128</span>];<br>    &#125;<br>    __syncthreads();<br><br>    <span class="hljs-keyword">if</span> (j &lt; <span class="hljs-number">64</span>)&#123;<br>        local_sum[j] += local_sum[j + <span class="hljs-number">64</span>];<br>    &#125;<br>    __syncthreads();<br><br>    <span class="hljs-keyword">if</span> (j &lt; <span class="hljs-number">32</span>)&#123;<br>        local_sum[j] += local_sum[j + <span class="hljs-number">32</span>];<br>    &#125;<br>    __syncthreads();<br><br>    <span class="hljs-keyword">if</span> (j &lt; <span class="hljs-number">16</span>)&#123;<br>        local_sum[j] += local_sum[j + <span class="hljs-number">16</span>];<br>    &#125;<br>    __syncthreads();<br><br>    <span class="hljs-keyword">if</span>(j &lt; <span class="hljs-number">8</span>)&#123;<br>        local_sum[j] += local_sum[j + <span class="hljs-number">8</span>];<br>    &#125;<br>    __syncthreads();<br><br>    <span class="hljs-keyword">if</span>(j &lt; <span class="hljs-number">4</span>)&#123;<br>        local_sum[j] += local_sum[j + <span class="hljs-number">4</span>];<br>    &#125;<br>    __syncthreads();<br><br>    <span class="hljs-keyword">if</span>(j &lt; <span class="hljs-number">2</span>)&#123;<br>        local_sum[j] += local_sum[j + <span class="hljs-number">2</span>];<br>    &#125;<br>    __syncthreads();<br><br>    <span class="hljs-keyword">if</span>(j == <span class="hljs-number">0</span>)&#123;<br>        sum[i] = local_sum[<span class="hljs-number">0</span>] + local_sum[<span class="hljs-number">1</span>];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><blockquote><p>这里代码是线程并行的， 如果不加__syncthreads(), 有的代码运行到了j &lt; 32,而有的才运行到 j &lt; 64,这就导致了归约顺序出现了问题。</p></blockquote><p>我们可以进一步优化这个代码，因为线程组是以32个为单位进行了， 一个线程组内部本身就是同步的。在j &lt; 32的时候，不需要加入sync..</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__void <span class="hljs-title">parallel_sum</span><span class="hljs-params">(<span class="hljs-type">int</span> *sum, <span class="hljs-type">int</span> <span class="hljs-type">const</span>* arr, <span class="hljs-type">int</span> n)</span></span>&#123;<br>    __shared__ <span class="hljs-type">int</span> local_sum[<span class="hljs-number">1024</span>];<br><br>    <span class="hljs-type">int</span> i = threadIdx.x;<br>    <span class="hljs-type">int</span> j = blockIdx.x;<br><br>    local_sum[j] = arr[i * <span class="hljs-number">1024</span> + j];<br>    __syncthreads();<br>    <br>    <span class="hljs-keyword">if</span> (j &lt; <span class="hljs-number">512</span>)&#123;<br>        local_sum[j] += local_sum[j + <span class="hljs-number">512</span>];<br>    &#125;<br>    __syncthreads();<br><br>    <span class="hljs-keyword">if</span> (j &lt; <span class="hljs-number">256</span>)&#123;<br>        local_sum[j] += local_sum[j + <span class="hljs-number">256</span>];<br>    &#125;<br>    __syncthreads();<br><br>    <span class="hljs-keyword">if</span> (j &lt; <span class="hljs-number">128</span>)&#123;<br>        local_sum[j] += local_sum[j + <span class="hljs-number">128</span>];<br>    &#125;<br>    __syncthreads();<br><br>    <span class="hljs-keyword">if</span> (j &lt; <span class="hljs-number">64</span>)&#123;<br>        local_sum[j] += local_sum[j + <span class="hljs-number">64</span>];<br>    &#125;<br>    __syncthreads();<br><br>    <span class="hljs-keyword">if</span> (j &lt; <span class="hljs-number">32</span>)&#123;<br>        local_sum[j] += local_sum[j + <span class="hljs-number">32</span>];<br>    &#125;<br><br>    <span class="hljs-keyword">if</span> (j &lt; <span class="hljs-number">16</span>)&#123;<br>        local_sum[j] += local_sum[j + <span class="hljs-number">16</span>];<br>    &#125;<br><br>    <span class="hljs-keyword">if</span>(j &lt; <span class="hljs-number">8</span>)&#123;<br>        local_sum[j] += local_sum[j + <span class="hljs-number">8</span>];<br>    &#125;<br><br>    <span class="hljs-keyword">if</span>(j &lt; <span class="hljs-number">4</span>)&#123;<br>        local_sum[j] += local_sum[j + <span class="hljs-number">4</span>];<br>    &#125;<br><br>    <span class="hljs-keyword">if</span>(j &lt; <span class="hljs-number">2</span>)&#123;<br>        local_sum[j] += local_sum[j + <span class="hljs-number">2</span>];<br>    &#125;<br><br>    <span class="hljs-keyword">if</span>(j == <span class="hljs-number">0</span>)&#123;<br>        sum[i] = local_sum[<span class="hljs-number">0</span>] + local_sum[<span class="hljs-number">1</span>];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="线程组分歧"><a href="#线程组分歧" class="headerlink" title="线程组分歧"></a>线程组分歧</h2><p>在 NVIDIA GPU 中，基本的调度单位是 Warp（线程束&#x2F;线程组），一个 Warp 包含 32 个线程。<br>线程组分歧是指：当同一个 Warp 中的 32 个线程在执行代码时，遇到了条件分支（如 if-else、switch 或 while），且一部分线程走向了 A 分支，另一部分线程走向了 B 分支。由于一个 Warp 在同一时刻只能执行同一条指令，硬件无法让线程 0 跑 if 的同时让线程 1 跑 else。</p><blockquote><p>当分歧发生时，GPU 硬件会采取“牺牲时间”的策略：</p><ol><li>执行分支 A：此时，所有走向分支 B 的线程会被屏蔽（Masked），处于空闲等待状态。</li><li>执行分支 B：此时，所有走向分支 A 的线程被屏蔽，轮到分支 B 的线程工作。</li><li>合并：两个分支都跑完后，32 个线程重新汇合，继续执行后面的指令。</li><li>结果： 原本应该并行完成的任务，因为分歧变成了串行执行。如果 if 和 else 各占一半，那么该 Warp 的理论计算性能直接损失 50%。</li></ol></blockquote><p>所以我们上边的一段代码实际上还可以进行优化，将<code>j &lt; 32</code>的部分都合并为一个，避免了线程分歧：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><br><span class="hljs-keyword">if</span>(j &lt; <span class="hljs-number">32</span>)&#123;<br>    local_sum[j] += local_sum[j + <span class="hljs-number">32</span>];<br>    local_sum[j] += local_sum[j + <span class="hljs-number">16</span>];<br>    local_sum[j] += local_sum[j + <span class="hljs-number">8</span>];<br>    local_sum[j] += local_sum[j + <span class="hljs-number">4</span>];<br>    local_sum[j] += local_sum[j + <span class="hljs-number">2</span>];<br><br>    <span class="hljs-keyword">if</span>(j == <span class="hljs-number">0</span>)&#123;<br>        sum[i] = local_sum[<span class="hljs-number">0</span>] + local_sum[<span class="hljs-number">1</span>];<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><h2 id="寄存器打翻-register-spill"><a href="#寄存器打翻-register-spill" class="headerlink" title="寄存器打翻(register spill)"></a>寄存器打翻(register spill)</h2><h3 id="板块中线程数量太多"><a href="#板块中线程数量太多" class="headerlink" title="板块中线程数量太多"></a>板块中线程数量太多</h3><ul><li>GPU一个板块中的线程，共享一个共同的寄存器仓库（实际上也是一段比较小的内存）， 所以当把模块中的线程数量（blockDim）太多的时候，会导致每个线程分配到的寄存器数量急剧缩小。另一方面， 如果程序需要大量的寄存器，就没有办法全部装在高效的寄存器仓库里，导致一部分寄存器“打翻”到一级缓存中，这些寄存器与寄存器仓库中的读写速度就不一致，相对而言就低效</li><li>如果线程局部分配了一个数组，并通过动态下标访问，那么这个数组会被分配到一级缓存中，因为寄存器不能动态寻址。</li><li>对于Fermi架构， 每个线程最多有63个寄存器。</li></ul><h3 id="板块中的线程太少"><a href="#板块中的线程太少" class="headerlink" title="板块中的线程太少"></a>板块中的线程太少</h3><p>每个SM一次调度板块中的一个线程组（warp），也就是32个线程。当线程陷入内存等待的时候，可以切换到另外一个线程，这样就算一个warp的内存延迟就被另外一个warp隐藏起来了。因此如果线程数量太少，则无法通过多个warp之间的调度来隐藏内存等待的延迟。</p><blockquote><p>block中的线程数量最好是32的整数倍， 因为如果是33个线程的情况下， 第二个warp中只有一个线程，非常浪费。</p></blockquote><p>综合上面的情况：对于使用寄存器少、访存为主的核函数，使用大的blockDim为宜。反之，使用较小的blockDim。</p><h2 id="Example矩阵转置"><a href="#Example矩阵转置" class="headerlink" title="Example矩阵转置"></a>Example矩阵转置</h2><p>首先实现一个简单的矩阵转置版本用一维数组的方式存储。[nx, ny] -&gt; [ny, nx]</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">typename</span> T&gt;</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">parallel_transpose</span><span class="hljs-params">(T* out, T* in,<span class="hljs-type">int</span> nx, <span class="hljs-type">int</span> ny)</span></span>&#123;<br><br>    <span class="hljs-type">int</span> linearized = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-keyword">if</span> (linearized &gt; nx * ny) <span class="hljs-keyword">return</span>;<br>    <span class="hljs-type">int</span> row = linearized / nx;<br>    <span class="hljs-type">int</span> col = linearized % nx;<br><br>    <span class="hljs-keyword">if</span> (row &lt; ny &amp;&amp; col &lt; nx) &#123;<br>        out[col * ny + row] = in[row * nx + col];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这段代码对于内存的访问仍不够高效， 因为in&#x2F;out都存在于GPU的显存当中，并且对于out的访问是跨步的，不符合内存局部性原理。这个问题可以通过板块共享内存解决。下边这段代码通过跨blockSize步数来进行访存(实际和blockDim没什么区别)</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">typename</span> T, <span class="hljs-type">int</span> blockSize </span>= <span class="hljs-number">32</span>&gt;<br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">parallel_transpose</span><span class="hljs-params">(T* out, T* in, <span class="hljs-type">int</span> nx, <span class="hljs-type">int</span> ny)</span></span>&#123;<br>    <span class="hljs-comment">//[nx, ny] -&gt; [nx, ny] -&gt; [ny, nx]</span><br>    <span class="hljs-comment">//这里使用以下二维的blockIdx， 对于y方向这种非连续的访存来说比较简单</span><br><br>    <span class="hljs-type">int</span> x = blockIdx.x * blockSize + threadIdx.x;<br>    <span class="hljs-type">int</span> y = blockIdx.y * blockSize + threadIdx.y;<br>    <span class="hljs-keyword">if</span> (x &gt;= nx || y &gt;= ny) <span class="hljs-keyword">return</span>;<br>    __shared__ T memory[blockSize * blockSize];<br>    <span class="hljs-comment">//第一步从in上连续的读取数据到共享内存</span><br>    <br>    memory[threadIdx.y * blockSize + threadIdx.x] = in[y * nx + x];<br>    __syncthreads();<br><br>    <span class="hljs-comment">// 转置之后的x, y坐标</span><br>    <span class="hljs-type">int</span> rx = blockIdx.y * blockSize + threadIdx.x;<br>    <span class="hljs-type">int</span> ry = blockIdx.x * blockSize + threadIdx.y;<br>    <span class="hljs-comment">// 跨步的从共享内存上读</span><br>    <span class="hljs-keyword">if</span> (rx &lt; ny &amp;&amp; ry &lt; nx) &#123; <span class="hljs-comment">// 必须加上这个判断</span><br>        out[ry * ny + rx] = memory[threadIdx.x * blockSize + threadIdx.y];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><blockquote><p>这里比较反直觉的是为什么多了一步的搬运步骤，反而要比直接从in -&gt; out快呢<br>gemini:<br>GPU 读写全局显存（Global Memory）时，不是一个线程一个线程读的，而是 Warp（32个线程） 一起读。</p><p>合并访问（Coalesced）：如果 32 个线程访问的是连续的 128 字节，硬件&gt;只需要 1 次内存事务。</p><p>跨步访问（Strided）：如果 32 个线程访问的地址散落在各地（比如转置时的列访问），硬件可能需要 32 次内存事务。</p><p>结论：跨步访问的带宽浪费可能高达 32 倍。</p><p>那么这样看起来像是从显存将数据搬移到共享内存中的速度要比从显存到显存快，事实是这样吗？</p><p>在指令的条数上，确实是显存 -&gt; 共享内存 -&gt; 显存的比较长(数据需要从显存搬移到寄存器中再进入到共享内存上)，不过现在的GPU似乎可以省去搬到寄存器这个步骤（待求证）</p><p>真正使得共享内存快的原因是：全局内存访问是以32&#x2F;128字节为一个整体为单位访问的，如果跨步很大， 但是只读取一个数据（比如int），那么有效的数据只有4&#x2F;128，损失的大量的带宽。</p></blockquote><h2 id="Bank-Conflict"><a href="#Bank-Conflict" class="headerlink" title="Bank Conflict"></a>Bank Conflict</h2><p>前一节实现了一个简单的矩阵转置的例子，但是其中仍旧有一个问题，GPU的shared_memory是按照一个个bank为单位进行划分的，总共会划分为32个banks，而线程的访存方式为 。我们期望的方式应该是两个不同的线程i与线程j的访存不冲突，即i与j同时访问不同的bank（如果访问同一个bank，bank内部则需要串行化处理，否则会带来data-race）。</p><p>$$\text{Bank Index} &#x3D; (\text{Address} &#x2F; 4\text{ bytes}) \pmod{32}$$</p><blockquote><p>PS 就是说</p><ul><li>arr[0], arr[32], arr[64]…一系列的数据会位于bank_0</li><li>arr[1], arr[33],arr[65]…会位于bank_1</li></ul></blockquote><p>那么在我们转置的过程中，一个warp对于全局内存的访问方式恰好就是这种按<em>列</em>读取，导致一个warp的所有线程都在同时的读取同一个bank。解决这个问题的方式为padding,让共享内存多出一行来，这样就可以恰好的让每一个线程都”错位”。</p><p>给出没有bank conflict的代码：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">typename</span> T, <span class="hljs-type">int</span> blockSize </span>= <span class="hljs-number">32</span>&gt;<br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">parallel_transpose</span><span class="hljs-params">(T* out, T* in, <span class="hljs-type">int</span> nx, <span class="hljs-type">int</span> ny)</span> </span>&#123;<br>    <span class="hljs-comment">// 这样每一行的起始地址在 Bank 中会产生“位移”，从而避开冲突</span><br>    __shared__ T memory[blockSize * (blockSize + <span class="hljs-number">1</span>)];<br><br>    <span class="hljs-comment">// 1. 计算原矩阵 in 的读取坐标</span><br>    <span class="hljs-type">int</span> x = blockIdx.x * blockSize + threadIdx.x;<br>    <span class="hljs-type">int</span> y = blockIdx.y * blockSize + threadIdx.y;<br><br>    <span class="hljs-keyword">if</span> (x &lt; nx &amp;&amp; y &lt; ny) &#123;<br>        <span class="hljs-comment">// 写入共享内存：由于每一行长度是 blockSize + 1</span><br>        memory[threadIdx.y * (blockSize + <span class="hljs-number">1</span>) + threadIdx.x] = in[y * ny + x];<br>    &#125;<br>    __syncthreads();<br><br>    <span class="hljs-comment">// 2. 计算转置矩阵 out 的写入坐标</span><br>    <span class="hljs-type">int</span> rx = blockIdx.y * blockSize + threadIdx.x; <br>    <span class="hljs-type">int</span> ry = blockIdx.x * blockSize + threadIdx.y;<br><br>    <span class="hljs-keyword">if</span> (rx &lt; ny &amp;&amp; ry &lt; nx) &#123;<br>        <span class="hljs-comment">// 跨步从共享内存读：由于之前存入时用了 padding</span><br>        <span class="hljs-comment">// 现在的读取索引：threadIdx.x * (blockSize + 1) + threadIdx.y</span><br>        <span class="hljs-comment">// 这一步在原代码中会导致 32 路 Bank Conflict，现在被 padding 完美化解</span><br>        out[ry * ny + rx] = memory[threadIdx.x * (blockSize + <span class="hljs-number">1</span>) + threadIdx.y];<br>        <span class="hljs-comment">// 这里线程0会读取 memory[0] - bank_0, 线程1会读取memory[33] - bank_1..，从而避免了冲突。</span><br>        <span class="hljs-comment">// 如果没有padding threadIdx.x逐步增加为0 ，1 但是读取的索引为0 ，32(threadIdx.x * blockSize + threadIdx.y)</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>CUDA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RoPE位置编码</title>
    <link href="/2025/12/22/RoPE/"/>
    <url>/2025/12/22/RoPE/</url>
    
    <content type="html"><![CDATA[<h1 id="旋转位置编码-RoPE"><a href="#旋转位置编码-RoPE" class="headerlink" title="旋转位置编码 RoPE"></a>旋转位置编码 RoPE</h1><h2 id="标准Transformer绝对位置编码"><a href="#标准Transformer绝对位置编码" class="headerlink" title="标准Transformer绝对位置编码"></a>标准Transformer绝对位置编码</h2><p>标准 Transformer 的位置编码通常采用绝对位置编码，也就是对于一句话中每个词（token）的位置：</p><p>$$<br>p_{k,2i}&#x3D;\sin\left(\frac{k}{10000^{\frac{2i}{d}}}\right)<br>$$<br>$$<br>p_{k,2i+1}&#x3D;\cos\left(\frac{k}{10000^{\frac{2i}{d}}}\right)<br>$$</p><p>说明：</p><ul><li>$k$ 表示 token 在序列中的位置索引（通常从 $0$ 开始），即 $k&#x3D;0,1,\dots,L-1$</li><li>$d$ 为 embedding 的维度，$i&#x3D;0,1,\dots,\frac{d}{2}-1$. 对每个 $i$，两个分量索引为 $(2i,2i+1)$，偶数维用 $\sin$，奇数维用 $\cos$</li></ul><p>例子：设 $d&#x3D;6$，则索引对为 $(0,1),(2,3),(4,5)$. 第三个 token（若从 0 开始，则 $k&#x3D;2$）在 $i&#x3D;1$ 时对应的两个分量为 $2i&#x3D;2$ 和 $2i+1&#x3D;3$：<br>$$<br>p_{2,2}&#x3D;\sin\left(\frac{2}{10000^{2&#x2F;6}}\right)<br>$$<br>$$<br>p_{2,3}&#x3D;\cos\left(\frac{2}{10000^{2&#x2F;6}}\right)<br>$$</p><p>关于不同句子中相同位置：<br>这里公式中的2i, 2i + 1, 分别表示第k个token的位置编码维度(需要与token的embedding保持一致， 比如这里token embedding是100维的， 那么这个token的位置编码的计算方式则为i &#x3D; 0-50，逐一按上面的公式计算得到不同位置的编码向量)。如果在不同的句子当中，位置3与位置3的位置编码向量就是一样的。</p><h2 id="RoPE相对位置编码"><a href="#RoPE相对位置编码" class="headerlink" title="RoPE相对位置编码"></a>RoPE相对位置编码</h2><p>根据Attention的计算公式，实际在标准Transformer的计算QK点积的时候(embedding + pos) * (embedding + pos)， 引入了无关的交叉项 也就是 embedding * pos 这对于模型来说可能是没有意义的。<br>$$<br>Attention(Q,K,V) &#x3D; softmax(\frac{QK^T}{\sqrt{d}})V<br>$$</p><p>在RoPE中，我们对每一个token的embedding, $x_m, x_n$，(分别表示位置是m和n的两个token)，乘上了一个旋转系数 $e^{ix\theta}$，这里的x表示向量的位置（也就是m&#x2F;n）。</p><p>经过Q&#x2F;K矩阵的向量就变成了下边的形式 $x_m’ &#x3D; W_qx_m e^{im\theta}\space , x_n’ &#x3D; W_kx_n e^{in\theta}$。将$W_qx_m 与 W_kx_n$先计算，可以表示为$q_m, k_n$。</p><p>这里以二维的嵌入矩阵为例<br>$$<br>q_m &#x3D; \begin{pmatrix}<br>    W_q^{11} &amp; W_q^{12} \<br>    W_q^{21} &amp; W_q^{22}<br>\end{pmatrix} \begin{pmatrix}<br>x_m^1 \<br>x_m^2<br>\end{pmatrix} &#x3D; \begin{pmatrix}p_m^1 \ p_m^2 \end{pmatrix}<br>$$<br>二维的矩阵可以表示成为一个虚数的形式(欧拉公式)。</p><p>$$<br>x_m^{^{\prime}}&#x3D;W_qx_me^{im\theta}&#x3D;(W_qx_m)e^{im\theta}&#x3D;q_me^{im\theta}&#x3D;<br>\begin{pmatrix}<br>cos(m\theta) &amp; -sin(m\theta) \<br>sin(m\theta) &amp; cos(m\theta)<br>\end{pmatrix}<br>\begin{pmatrix}<br>q_m^1 \<br>q_m^2<br>\end{pmatrix}<br>$$<br>同理对于$x_n^{\prime}$:<br>$$<br>x_{n}^{^{\prime}}&#x3D;W_{k}x_{n}e^{in\theta}\quad&#x3D;(W_{k}x_{n})e^{in\theta}&#x3D;q_{k}e^{in\theta}\quad&#x3D;<br>\begin{pmatrix}<br>cos(n\theta) &amp; -sin(n\theta) \<br>sin(n\theta) &amp; cos(n\theta)<br>\end{pmatrix}<br>\begin{pmatrix}<br>k_{n}^{1} \<br>k_{n}^{2}<br>\end{pmatrix}\quad<br>$$<br>当计算这两个值的点积时：<br>$$<br>x_{m}^{\prime T}x_{n}^{^{\prime}}&#x3D;\left(q_{m}^{1}q_{m}^{2}\right)<br>\begin{pmatrix}<br>cos((m-n)\theta) &amp; -sin((m-n)\theta) \<br>sin((m-n)\theta) &amp; cos((m-n)\theta)<br>\end{pmatrix}<br>\begin{pmatrix}<br>k_{n}^{1} \<br>k_{n}^{2}<br>\end{pmatrix}\quad<br>$$<br>那么我们如何扩展到多维呢,给出下边的这个矩阵:</p><p>$$<br>\begin{pmatrix}<br>\cos m\theta_0 &amp; -\sin m\theta_0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 \<br>\sin m\theta_0 &amp; \cos m\theta_0 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; \cos m\theta_1 &amp; -\sin m\theta_1 &amp; \cdots &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; \sin m\theta_1 &amp; \cos m\theta_1 &amp; \cdots &amp; 0 &amp; 0 \<br>\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; \cos m\theta_{d&#x2F;2-1} &amp; -\sin m\theta_{d&#x2F;2-1} \<br>0 &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; \sin m\theta_{d&#x2F;2-1} &amp; \cos m\theta_{d&#x2F;2-1}<br>\end{pmatrix}<br>\begin{pmatrix}<br>q_0 \<br>q_1 \<br>q_2 \<br>q_3 \<br>\vdots \<br>q_{d-2} \<br>q_{d-1}<br>\end{pmatrix}<br>$$</p>]]></content>
    
    
    
    <tags>
      
      <tag>Transformer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>设计模式-1 装饰器模式</title>
    <link href="/2025/09/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    <url>/2025/09/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<h1 id="装饰器模式"><a href="#装饰器模式" class="headerlink" title="装饰器模式"></a>装饰器模式</h1><p>简单的来说，就是为某一个类&#x2F;对象增加一些额外的功能，类似于Spring的AOP，执行方法增强。</p><h2 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h2><p>目标：学习装饰器模式<br>课题：<br><img src="/2025/09/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/request.png"><br>实现这样一个功能，在接收到post请求之后，为map添加一个<code>timestamp</code>字段，值为当前的时间戳(不依赖Spring的AOP)。</p><h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><p>为了实现这个装饰器，我们首先需要知道这里的map是怎么获取到的，这里直接打一个断点进入堆栈，对接口发送图中的请求。</p><p>在接口收到请求之后，我们很容易就可以定位到这个方法，进入这个方法中，发现有<code>getMethodArgumentValues</code>这个方法的调用。<br><img src="/2025/09/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/debug0.png"></p><p>点进这个方法，看到这个方法中关于<code>args</code>的赋值逻辑:交给<code>resolver.resolveArgument()</code>进行处理，那么这个真正的逻辑就藏在<code>resolver</code>中。<br><img src="/2025/09/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/debug1.png"><br>接着去看<code>resolvers</code>都是什么？ (<code>HandlerMethodArgumentResolverComposite</code>)<br><img src="/2025/09/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/debug2.png"><br>同时如果不加配置的情况下，<code>resolvers</code>的size应该是27个(这里就不截图了)。因此可以确定，我们如果想实现目标，需要添加一个自定义的resolver或者是对某一个resolver进行增强，也就符合装饰器模式的定义，也就需要再看看Spring是什么时候添加这些resolver的，点进去这个<code>HandlerMethodArgumentResolverComposite</code>给这几个<code>addResolver()</code>打上断点，再看看调用堆栈。<br><img src="/2025/09/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/debug3.png"><br>很容易定位到下边这些个箭头的方法~，这个<code>getDefaultArgumentResolvers</code>是一坨巨大的石山(一个个new出来然后再add)。<br><img src="/2025/09/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/debug4.png"></p><p>接着再回来，这里的<code>HandlerMethodArgumentResolverComposite</code>也是一种装饰器模式的实现，即它本身是一个<code>...resolver</code>，里边又塞了一个<code>resolver</code>的list，在实际执行resolve方法的时候，他先获取支持当前param的resolver再丢给对应的resolver进行处理。<br><img src="/2025/09/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/debug5.png"><br><img src="/2025/09/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/debug6.png"></p><p>那么带有<code>@RequestBody</code>注解的param是通过哪一个<code>resolver</code>进行处理的，答案是<code>RequestResponseBodyMethodProcessor</code>，这时就比较简单了，我们需要查看一下这个resolver是怎么进行supportArgument的,再自定义一个resolver进行增强。<br><img src="/2025/09/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/debug7.png"></p><p>那么接下来我们需要做两件事情：</p><ol><li>检查一下怎么supportArgument</li><li>依据supportArgument的结果，自行魔改一下。</li><li>看一下怎么把我们装饰之后的东西放到先前的resolvers中</li></ol><p>可以看到，他是直接检查是否有<code>@RequestBody</code>注解，来判断是否<code>supportArgument</code>，那么controller中的map就是在这个类下的<code>resolveArgument()</code>中创建的，到这，我们就大体可以实现目标了。<br><img src="/2025/09/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/debug8.png"><br>简单写一下我们的装饰器：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> com.liuyan.wrapperspringboot.decorater;<br><br><span class="hljs-keyword">import</span> com.liuyan.wrapperspringboot.annotation.TimeStampRequestBody;<br><span class="hljs-keyword">import</span> org.springframework.core.MethodParameter;<br><span class="hljs-keyword">import</span> org.springframework.web.bind.support.WebDataBinderFactory;<br><span class="hljs-keyword">import</span> org.springframework.web.context.request.NativeWebRequest;<br><span class="hljs-keyword">import</span> org.springframework.web.method.support.HandlerMethodArgumentResolver;<br><span class="hljs-keyword">import</span> org.springframework.web.method.support.ModelAndViewContainer;<br><br><span class="hljs-keyword">import</span> java.util.Map;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 自定义的resolver，实际上是对RequestResponseBodyMethodProcessor进行装饰</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">TimeStampMethodProcessor</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">HandlerMethodArgumentResolver</span> &#123;<br><br>HandlerMethodArgumentResolver processor;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 判断一下含有我们自定义注解的参数</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@param</span> parameter</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@return</span></span><br><span class="hljs-comment"> */</span><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">supportsParameter</span><span class="hljs-params">(MethodParameter parameter)</span> &#123;<br><span class="hljs-keyword">return</span> parameter.hasParameterAnnotation(TimeStampRequestBody.class);<br>&#125;<br><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> Object <span class="hljs-title function_">resolveArgument</span><span class="hljs-params">(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br><span class="hljs-comment">//直接交给我们装饰的对象进行处理</span><br><span class="hljs-type">Object</span> <span class="hljs-variable">result</span> <span class="hljs-operator">=</span> processor.resolveArgument(parameter, mavContainer, webRequest, binderFactory);<br><span class="hljs-keyword">if</span> (!(result <span class="hljs-keyword">instanceof</span> Map)) &#123;<br><span class="hljs-keyword">return</span> result;<br>&#125;<br>((Map) result).put(<span class="hljs-string">&quot;timeStamp&quot;</span>, System.currentTimeMillis());<br><span class="hljs-keyword">return</span> result;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>那么目标1，2都已经实现了，接着我们要看看怎么把我们的decorater放到resolvers中。还记得我们我们之前说的一段石山代码吗，那里就是初始化这里<code>resolvers</code>代码的敌方，不过我们需要的是添加到自定义的resolver,截一部分图看看吧~。<br><img src="/2025/09/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/debug9.png"><br>点进去看看我们要怎么添加，就可以完成目标咯，但是图中的这个类只有他的set方法，那么还需要看看这个set是什么时候被调用的，给set方法打一下断点.<br><img src="/2025/09/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/debug10.png"><br>调用他的类名字叫<code>WebMvcConfigurationSupport</code>，大概率是配置类，再根据调用点点点。<br><img src="/2025/09/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/debug11.png"><br><img src="/2025/09/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/debug12.png"><br>这里就是添加<code>argumentResolver</code>的地方，还是一个经典的懒加载，那么再进入一下这里的方法调用，发现这是一个接口，那么找找实现类，其中只有一个<code>DelegatingWebMvcConfiguration</code>，仔细观察一下这个类的代码，又是一个经典的装饰器实现，那我们势必要再看看他装饰的类(<code>WebMvcConfigurerComposite</code>)中<code>addArgumentResolver</code>的实现了，可以找到一个<code>addWebMvcConfigurers</code>的方法被调用，就需要看看<code>DelegatingWebMvcConfiguration</code>是怎么调用这个方法的了。<br><img src="/2025/09/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/debug13.png"><br>这里就可以看到了，他收集了所有实现了<code>WebMvcConfigurer</code>接口的类，加入到我们期望的list当中，写一个configurer类，实现<code>WebMvcConfigurer</code>接口，在<code>addArgumentResolvers</code>方法中添加我们的decorater。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Configuration</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">CustomWebConfigurer</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">WebMvcConfigurer</span> &#123;<br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 加入我们自定义的解析器</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@param</span> resolvers</span><br><span class="hljs-comment"> */</span><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">addArgumentResolvers</span><span class="hljs-params">(List&lt;HandlerMethodArgumentResolver&gt; resolvers)</span> &#123;<br>resolvers.add(<span class="hljs-keyword">new</span> <span class="hljs-title class_">TimeStampMethodProcessor</span>());<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>重新启动一下验证有没有加入。<br><img src="/2025/09/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/debug14.png"><br>可以看到是已经加入了，但是现在还有一个问题，我们的自定义类中的processor是没有赋值了，那么该怎么获取到这个东西呢，因为我们原本包装的这个对象是通过new关键字直接加入到对应list当中的，我们需要拿到持有这个list的容器，通过遍历的方式来初始化我们的processor。<code>RequestMappingHandlerAdapter</code>这个类已经交给Spring容器进行管理了，那么事情就很简单。</p><p>不过我们没有把自己的类定义成Bean，所以还用不了<code>@Autowired</code>，可以直接通过ApplicationContext来获取，贴一小部分代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">setupProcessor</span><span class="hljs-params">()</span> &#123;<br><span class="hljs-keyword">if</span> (processor != <span class="hljs-literal">null</span>) &#123;<br><span class="hljs-keyword">return</span>;<br>&#125;<br><span class="hljs-type">RequestMappingHandlerAdapter</span> <span class="hljs-variable">adapter</span> <span class="hljs-operator">=</span> <span class="hljs-built_in">this</span>.applicationContext.getBean(RequestMappingHandlerAdapter.class);<br><span class="hljs-keyword">for</span> (HandlerMethodArgumentResolver resolver : adapter.getArgumentResolvers()) &#123;<br><span class="hljs-keyword">if</span> (resolver <span class="hljs-keyword">instanceof</span> RequestResponseBodyMethodProcessor) &#123;<br>processor = resolver;<br>&#125;<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>至此，我们的目标就完成了，结果如下图<br><img src="/2025/09/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/res.png"></p><p>代码链接: <a href="https://github.com/JisoLya/DesignPattern/tree/master/WrapperSpringBoot">https://github.com/JisoLya/DesignPattern/tree/master/WrapperSpringBoot</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>DesignPattern</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HugeGraph重构-store-gRPC模块解析</title>
    <link href="/2025/07/13/HugeGraph%E9%87%8D%E6%9E%84-store-gRPC%E6%A8%A1%E5%9D%97%E8%A7%A3%E6%9E%90/"/>
    <url>/2025/07/13/HugeGraph%E9%87%8D%E6%9E%84-store-gRPC%E6%A8%A1%E5%9D%97%E8%A7%A3%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h1 id="hg-store-rpc模块"><a href="#hg-store-rpc模块" class="headerlink" title="hg-store-rpc模块"></a>hg-store-rpc模块</h1><p>本模块采用了gRPC作为通信协议，为了更好的了解rpc的过程，我们需要先了解一下什么是gRPC。</p><h2 id="什么是gRPC"><a href="#什么是gRPC" class="headerlink" title="什么是gRPC"></a>什么是gRPC</h2><p>RPC，全称<code>Remote Procedure Call</code>，中文译为远程过程调用。通俗地讲，使用RPC进行通信，调用远程函数就像调用本地函数一样，RPC底层会做好数据的序列化与传输，从而能使我们更轻松地创建分布式应用和服务。</p><p>而gRPC是RPC的一种，是由Google免费开源的一个RPC通信协议，我们只需要好API的Request与Response，其余的事情由gRPC帮我们实现。<br><img src="/2025/07/13/HugeGraph%E9%87%8D%E6%9E%84-store-gRPC%E6%A8%A1%E5%9D%97%E8%A7%A3%E6%9E%90/gRpc.png" alt="gRPC"><br>默认的情况下，gRPC使用Protocol Buffers作为接口定义语言(IDL)，本质上是一个序列化结构化数据的过程，比如Java中的<code>class</code>或者是cpp中的<code>struct</code>&#x2F;<code>class</code>的过程，在使用的过程中你也可以使用JSON作为序列化，可以在不同的服务之间进行通信。</p><p>简单的来说，gRpc就是一套由Google实现的服务通信框架更多的详细信息可以参考：<br><a href="https://grpc.org.cn/docs/what-is-grpc/introduction/">https://grpc.org.cn/docs/what-is-grpc/introduction/</a></p><h2 id="gRPC-In-HugeGraph"><a href="#gRPC-In-HugeGraph" class="headerlink" title="gRPC In HugeGraph"></a>gRPC In HugeGraph</h2><p>作为一个存算分离架构的图数据库，不同的模块需要部署在不同的设备上，那么此时服务间的调用就需要用到RPC，HugeGraph采用了gRPC作为通信框架。</p><p>这里主要说明一下<code>store</code>模块的gRPC定义(定义在<code>hugegraph-store/huge-store-grpc</code>这个模块下)<br>下边是各个<code>.proto</code>文件的含义</p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs 1c">hg<span class="hljs-punctuation">-</span>store<span class="hljs-punctuation">-</span>grpc/src/main/proto/<br>         <span class="hljs-string">|</span><br>         <span class="hljs-string">|- graphpb.proto (定义 GraphStore 服务，用于流式扫描图分区中的顶点和边)</span><br>         <span class="hljs-string">|</span><br>         <span class="hljs-string">|- healthy.proto (定义 Healthy 服务，用于健康检查)</span><br>         <span class="hljs-string">|</span><br>         <span class="hljs-string">|- query.proto (定义 QueryService 服务，用于复杂的聚合下推查询)</span><br>         <span class="hljs-string">|</span><br>         <span class="hljs-string">|- store_common.proto (定义通用的数据结构和枚举)</span><br>         <span class="hljs-string">|</span><br>         <span class="hljs-string">|- store_session.proto (定义 HgStoreSession 服务，提供核心 CRUD 和事务管理)</span><br>         <span class="hljs-string">|</span><br>         <span class="hljs-string">|- store_state.proto (定义 HgStoreState 服务，用于监控节点状态)</span><br>         <span class="hljs-string">|</span><br>         <span class="hljs-string">|- store_stream_meta.proto (定义流式扫描的元数据和复杂控制接口)</span><br></code></pre></td></tr></table></figure><p>下面主要关注一下这几个<code>.proto</code>文件的内容</p><ol><li><strong><code>graphpb.proto</code></strong><br>  文件中首先定义了一个rpc服务</li></ol>  <figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs protobuf"><span class="hljs-keyword">service </span><span class="hljs-title class_">GraphStore</span> &#123;<br>  <span class="hljs-function"><span class="hljs-keyword">rpc</span> ScanPartition(stream ScanPartitionRequest) <span class="hljs-keyword">returns</span> (stream ScanResponse)</span>&#123;&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>  这个rpc的请求与响应都以流式传输<br>  请求消息分为两种，分别是初始的扫描请求scan_request，或者是某一个请求的响应。<br>  <figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs protobuf"><span class="hljs-keyword">message </span><span class="hljs-title class_">ScanPartitionRequest</span>&#123;<br>  <span class="hljs-comment">//...</span><br>  RequestHeader header = <span class="hljs-number">1</span>;<br>  <span class="hljs-keyword">oneof</span> request &#123;<br>    Request scan_request = <span class="hljs-number">2</span>;<br>    Reply reply_request = <span class="hljs-number">4</span>;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><br>  接下来是<code>Request</code>的定义，依次指明了扫描的类型，分区信息以及用于过滤一些信息等。<br>  <figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs protobuf"><span class="hljs-keyword">message </span><span class="hljs-title class_">Request</span>&#123;<br>  ScanType scan_type = <span class="hljs-number">1</span>;<br>  <span class="hljs-type">string</span> graph_name = <span class="hljs-number">2</span>;<br>  <span class="hljs-type">uint32</span> partition_id = <span class="hljs-number">3</span>;<br>  <span class="hljs-type">uint32</span> start_code = <span class="hljs-number">4</span>;<br>  <span class="hljs-type">uint32</span> end_code = <span class="hljs-number">5</span>;<br>  <span class="hljs-comment">// Filter conditions</span><br>  <span class="hljs-type">string</span> condition = <span class="hljs-number">6</span>;<br>  <span class="hljs-type">string</span> table = <span class="hljs-number">7</span>;<br>  <span class="hljs-type">int64</span> limit = <span class="hljs-number">8</span>;<br>  <span class="hljs-type">int32</span> boundary = <span class="hljs-number">9</span>;<br>  <span class="hljs-type">bytes</span> position = <span class="hljs-number">10</span>;<br>  <span class="hljs-comment">// Return condition</span><br>  <span class="hljs-keyword">repeated</span> <span class="hljs-type">int64</span> properties = <span class="hljs-number">11</span>;<br>&#125;<br></code></pre></td></tr></table></figure></p><p>  响应消息<code>ScanResponse</code>，<em>repeated</em> 关键字表示每次响应是一个列表，而不是一个个的vertex或Edge。<br>  <figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs protobuf"><span class="hljs-keyword">message </span><span class="hljs-title class_">ScanResponse</span>&#123;<br>  ResponseHeader header = <span class="hljs-number">1</span>;<br>  <span class="hljs-comment">// Message Sequence Number</span><br>  <span class="hljs-type">int32</span>     seq_no = <span class="hljs-number">2</span>;<br>  <span class="hljs-keyword">repeated</span>  Vertex vertex = <span class="hljs-number">3</span>;<br>  <span class="hljs-keyword">repeated</span>  Edge edge = <span class="hljs-number">4</span>;<br>&#125;<br></code></pre></td></tr></table></figure><br>2. <strong><code>healthy.proto</code></strong><br>  文件中定义了一个简单的<code>Healthy</code>的RPC服务，用于健康检查。<br>  <figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs protobuf"><span class="hljs-keyword">service </span><span class="hljs-title class_">Healthy</span> &#123;<br>  <span class="hljs-function"><span class="hljs-keyword">rpc</span> IsOk(google.protobuf.Empty) <span class="hljs-keyword">returns</span> (StringReply) </span>&#123;&#125;<br>&#125;<br><br><span class="hljs-keyword">message </span><span class="hljs-title class_">StringReply</span> &#123;<br>  <span class="hljs-type">string</span> message = <span class="hljs-number">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure><br>3. <strong><code>query.proto</code></strong> –new<br>  这一个是在3.7版本中新增的proto文件，也是store-grpc这一模块的关键更新，这个proto中定义了支持查询下推功能的RPC消息。<br>  首先是服务的定义<br>  <figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs protobuf"><span class="hljs-keyword">service </span><span class="hljs-title class_">QueryService</span> &#123;<br>  <span class="hljs-function"><span class="hljs-keyword">rpc</span> query(stream QueryRequest) <span class="hljs-keyword">returns</span> (stream QueryResponse) </span>&#123;&#125;<br>  <span class="hljs-function"><span class="hljs-keyword">rpc</span> query0(QueryRequest) <span class="hljs-keyword">returns</span> (QueryResponse) </span>&#123;&#125;<br>  <span class="hljs-function"><span class="hljs-keyword">rpc</span> count(QueryRequest) <span class="hljs-keyword">returns</span> (QueryResponse) </span>&#123;&#125;<br>&#125;<br></code></pre></td></tr></table></figure><br>  分别定义了三个RPC服务，一个是以流的形式来接受请求与响应，一个简单的一元 RPC（即一个请求对应一个响应）。它适用于那些预计能快速返回结果的、较小的查询。最后则是一个计数请求，可以看作是对COUNT请求的优化。</p><p>  query中最关键的部分则是<code>stream QueryRequest</code>这个查询请求。<br>  <figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs protobuf"><span class="hljs-keyword">message </span><span class="hljs-title class_">QueryRequest</span>&#123;<br>  <span class="hljs-type">string</span> queryId = <span class="hljs-number">1</span>;<br>  <span class="hljs-type">string</span> graph = <span class="hljs-number">2</span>;<br>  <span class="hljs-type">string</span> table = <span class="hljs-number">3</span>;<br><br>  <span class="hljs-keyword">repeated</span> AggregateFunc functions = <span class="hljs-number">4</span>;<br>  <span class="hljs-comment">// 属性剪裁，如果为空，则返回所有的属性, aggregation 作为单独字段，不包含此列</span><br>  <span class="hljs-comment">// 如果有group by，应该是group by的子集</span><br>  <span class="hljs-keyword">repeated</span> <span class="hljs-type">bytes</span> property = <span class="hljs-number">5</span>;<br>  <span class="hljs-keyword">repeated</span> <span class="hljs-type">bytes</span> group_by = <span class="hljs-number">6</span>; <span class="hljs-comment">// group by的字段</span><br>  <span class="hljs-keyword">repeated</span> <span class="hljs-type">uint32</span> having = <span class="hljs-number">7</span>;   <span class="hljs-comment">// having 的过滤</span><br>  <span class="hljs-keyword">repeated</span> <span class="hljs-type">bytes</span> order_by = <span class="hljs-number">8</span>; <span class="hljs-comment">// order by 字段</span><br>  <span class="hljs-type">bool</span> sort_order = <span class="hljs-number">9</span>; <span class="hljs-comment">// asc or desc</span><br>  <span class="hljs-type">bool</span> null_property = <span class="hljs-number">10</span>; <span class="hljs-comment">// 不使用property，仅仅返回key</span><br><br>  ScanType scan_type = <span class="hljs-number">11</span>; <span class="hljs-comment">// 表扫描类型, 如果有索引，此项忽略</span><br><br>  <span class="hljs-keyword">repeated</span> ScanTypeParam scan_type_param = <span class="hljs-number">12</span>; <span class="hljs-comment">// id, prefix 只用到start</span><br><br>  DeDupOption dedup_option = <span class="hljs-number">13</span>;  <span class="hljs-comment">// 是否需要key消重</span><br><br>  <span class="hljs-type">bytes</span> condition = <span class="hljs-number">21</span>; <span class="hljs-comment">// condition</span><br>  <span class="hljs-type">bytes</span> position = <span class="hljs-number">24</span>;            <span class="hljs-comment">// 返回offset ~ offset + limit</span><br>  <span class="hljs-type">uint32</span> limit = <span class="hljs-number">23</span>;             <span class="hljs-comment">// page</span><br>  <span class="hljs-type">uint32</span> offset = <span class="hljs-number">25</span>;           <span class="hljs-comment">// offset</span><br><br>  <span class="hljs-type">double</span> sample_factor = <span class="hljs-number">31</span>; <span class="hljs-comment">// 抽样频率，应该小于等于1</span><br><br>  <span class="hljs-keyword">repeated</span> <span class="hljs-type">bytes</span> olap_property = <span class="hljs-number">32</span>; <span class="hljs-comment">// 读取的olap 属性</span><br><br>  <span class="hljs-comment">// 使用的索引, 第一层为or关系，第二层为 and关系</span><br>  <span class="hljs-comment">// indexes ((index,index) or (index, index))</span><br>  <span class="hljs-keyword">repeated</span> Index indexes = <span class="hljs-number">41</span>;<br><br>  <span class="hljs-type">bool</span> load_property_from_index = <span class="hljs-number">42</span>;<br>  <span class="hljs-type">bool</span> check_ttl = <span class="hljs-number">43</span>;<br>  <span class="hljs-comment">// 按照element的 label id group by</span><br>  <span class="hljs-type">bool</span> group_by_schema_label = <span class="hljs-number">44</span>;<br>&#125;<br></code></pre></td></tr></table></figure><br>  消息中比较重要的是<code>AggregateFunc</code>指明了聚合操作的函数类型，常见的如<code>COUNT</code>、<code>SUM</code>、<code>AVG</code>等；<code>property</code>告诉服务端只需要返回哪些属性（字段），而不是返回整个顶点或边的所有数据，以此减少网络传输量；而<code>group_by</code>、<code>having</code>、<code>order by</code>则类似于Mysql中的类似操作；<code>condition</code>则是指明了过滤条件类比Mysql中的where子句；</p><p>  最后则是<code>QueryResponse</code><br>  <figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs protobuf"><span class="hljs-keyword">message </span><span class="hljs-title class_">QueryResponse</span> &#123;<br>  <span class="hljs-type">string</span> query_id = <span class="hljs-number">1</span>;<br>  <span class="hljs-type">bool</span> is_ok = <span class="hljs-number">2</span>;<br>  <span class="hljs-type">bool</span> is_finished = <span class="hljs-number">3</span>;<br>  <span class="hljs-type">string</span> message = <span class="hljs-number">4</span>;<br>  <span class="hljs-keyword">repeated</span> Kv data = <span class="hljs-number">5</span>;<br>&#125;<br></code></pre></td></tr></table></figure><br>  关键字段为<code>is_finished</code>用来标记流式响应是否结束，<code>Kv data</code>则是以K-V的形式返回数据，需要注意的是，如果是聚合操作，那么返回的则会是聚合后的结果。</p><ol start="4"><li><strong><code>store_common.proto</code></strong> –updated<br>  这个proto文件主要定义了HugeGraph的gRPC中通用的一些数据结构与枚举类型</li></ol><ul><li>Key: 只包含一个 key 的结构。</li><li>Tkv: “Tabled Key-Value” 的缩写，即带所属表信息的键值对 (table, key, value)。</li><li>Tk: “Tabled Key” 的缩写，即带所属表信息的键 (table, key)。</li><li>Tp: “Tabled Prefix” 的缩写，即带所属表信息的前缀 (table, prefix)，用于前缀扫描。</li><li>Tse: “Tabled Start-End” 的缩写，即带所属表信息的范围 (table, start key, end key)，用于范围扫描。</li></ul><p>  在新版本中新添加了一个结构<code>TTLCleanRequest</code>，这个Request用于清理过期的数据，因而需要定位到数据所在的图&#x2F;分片&#x2F;表等信息，以及过期数据的IDs。<br>  <figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs protobuf"><span class="hljs-keyword">message </span><span class="hljs-title class_">TTLCleanRequest</span> &#123;<br>  <span class="hljs-type">string</span> graph = <span class="hljs-number">1</span>;<br>  <span class="hljs-type">int32</span> partitionId = <span class="hljs-number">2</span>;<br>  <span class="hljs-type">string</span> table = <span class="hljs-number">3</span>;<br>  <span class="hljs-keyword">repeated</span> <span class="hljs-type">bytes</span> ids = <span class="hljs-number">4</span>;<br>&#125;<br></code></pre></td></tr></table></figure></p><p>  其余的一些枚举则都可以见名知意，这里就不做解释了。</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
